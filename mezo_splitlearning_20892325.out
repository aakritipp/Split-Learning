Starting Split Learning Job
================================
Job ID: 20892325
Node: skl-a-48
Time: Tue Sep 23 05:29:26 AM EDT 2025
Working Directory: /home/al1745/Split-Learning/large_models
================================
All required files present
Configuration:
   Model: facebook/opt-125m
   Epochs: 1
   Batch Size: 16
   Max Length: 512
   Learning Rate: 1e-4

Starting server...
Server PID: 2483873
Waiting 45 seconds for server initialization...
Server is running
Starting client...
Waiting for server to finish...
STARTING ENHANCED SPLIT LEARNING SERVER
============================================================
  Configuration:
   Model: facebook/opt-125m
   Batch size: 16
   Max length: 512
   ZOO server: False
   ZOO client: False
   F1 method: micro
  Using device: cuda
  Loading tokenizer: facebook/opt-125m
  Tokenizer loaded successfully
  Creating models...
Full model ready; prefix-aware eval OFF by default (legacy behavior).
  Models created and synchronized
 Creating dataloaders...
Creating SQUAD dataset with MeZO hyperparameters...
Train examples: 1000
Dev examples: 500
Eval examples: 1000
Batch size: 16
Dataset sizes: Train=1000, Dev=500, Eval=1000
SQUAD dataloaders created successfully with custom collate function
   Train batches: 63
   Eval batches: 63
  Testing dataloader...
Dataloader test passed
   Batch keys: ['input_ids', 'attention_mask', 'labels', 'formatted_text', 'original_example']
   Batch shapes: ['input_ids: torch.Size([16, 512])', 'attention_mask: torch.Size([16, 512])', 'labels: torch.Size([16, 512])', 'formatted_text: 16', 'original_example: 16']
  Dataloaders created successfully
  Setting up optimizer...
✅ Optimizer ready
Setting up network...
  Debug - Server model info:
============================================================
SERVER READY - WAITING FOR CLIENT
============================================================
Server listening on localhost:12345
Start client with same parameters
============================================================
✅ Client connected from ('127.0.0.1', 33128)
Received client config: {'model_name': 'facebook/opt-125m', 'num_prefix': 5, 'lr': 0.0001, 'client_sgd': False, 'zoo_lr': 0.0001, 'mu': 0.0005, 'num_pert': 10, 'client_tuning': 'prefix', 'lora': {'r': 8, 'alpha': 16, 'dropout': 0.0, 'targets': 'q_proj,v_proj'}}
Starting training...

Epoch 1/1
   Starting split learning training (SGD)...
   Training configuration:
   Max steps: 1000
   Batch size: 16
   Learning rate: 0.0001
   Eval every: 1000 steps
